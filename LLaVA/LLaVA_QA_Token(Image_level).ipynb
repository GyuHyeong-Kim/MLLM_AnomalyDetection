{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "81c762ae-b265-425a-9ace-96b5346336e1",
   "metadata": {},
   "source": [
    "# # SigLIP Mask Token(Image-level) LLaVA 답변 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "60f284af-f4bf-4643-a1bd-3cea37b2cbd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from pathlib import Path\n",
    "from transformers import AutoProcessor, LlavaOnevisionForConditionalGeneration\n",
    "\n",
    "MASK_DIR = Path(\"/home/s2behappy4/data/gyuhyeong/code/siglip_mask_token/hazelnut/hole\")\n",
    "MODEL_ID = \"llava-hf/llava-onevision-qwen2-7b-ov-hf\"\n",
    "DEV      = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "DTYPE    = torch.bfloat16                      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a1705f7-ddfe-4235-a620-2fced8bf9048",
   "metadata": {},
   "outputs": [],
   "source": [
    "proc  = AutoProcessor.from_pretrained(MODEL_ID, trust_remote_code=True)\n",
    "llava = LlavaOnevisionForConditionalGeneration.from_pretrained(\n",
    "            MODEL_ID,\n",
    "            torch_dtype       = DTYPE,\n",
    "            device_map        = \"auto\",\n",
    "            low_cpu_mem_usage = True,\n",
    "            trust_remote_code = True\n",
    "        ).eval()\n",
    "\n",
    "TOK_IMG = proc.tokenizer.additional_special_tokens[0]      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "04ca0b66-6ad5-4261-aeb4-588f933548ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[000]  No, there is no anomaly in the image.\n",
      "[001]  No, there is no anomaly in the image.\n",
      "[002]  No, there is no anomaly in the image.\n",
      "[003]  No, there is no anomaly in the image.\n",
      "[004]  No, there is no anomaly in the image.\n",
      "[005]  No, there is no anomaly in the image.\n",
      "[006]  No, there is no anomaly in the image.\n",
      "[007]  No, there is no anomaly in the image.\n",
      "[008]  No, there is no anomaly in the image.\n",
      "[009]  No, there is no anomaly in the image.\n",
      "[010]  No, there is no anomaly in the image.\n",
      "[011]  No, there is no anomaly in the image.\n",
      "[012]  No, there is no anomaly in the image.\n",
      "[013]  No, there is no anomaly in the image.\n",
      "[014]  No, there is no anomaly in the image.\n",
      "[015]  No, there is no anomaly in the image.\n",
      "[016]  No, there is no anomaly in the image.\n",
      "[017]  No, there is no anomaly in the image.\n"
     ]
    }
   ],
   "source": [
    "def ask_llava(mask_tok: torch.Tensor) -> str:\n",
    "    v_emb = llava.multi_modal_projector(mask_tok.unsqueeze(0).to(DEV, DTYPE))  \n",
    "    M     = v_emb.size(1)\n",
    "\n",
    "    prompt = (TOK_IMG + \" \") * M + \"USER: Is there any anomaly in the image? (Yes / No)\\nASSISTANT:\"\n",
    "    tok_in = proc.tokenizer(prompt, return_tensors=\"pt\").to(DEV)\n",
    "    t_emb  = llava.get_input_embeddings()(tok_in.input_ids).to(DTYPE)           \n",
    "\n",
    "    inp_emb   = torch.cat([v_emb, t_emb], dim=1)                                \n",
    "    att_mask  = torch.cat([torch.ones(1, M, dtype=torch.long, device=DEV),\n",
    "                           tok_in.attention_mask], dim=1)\n",
    "\n",
    "    out = llava.generate(\n",
    "            inputs_embeds   = inp_emb,\n",
    "            attention_mask  = att_mask,\n",
    "            max_new_tokens  = 30,\n",
    "            do_sample       = False,     \n",
    "            eos_token_id    = proc.tokenizer.eos_token_id,\n",
    "            pad_token_id    = proc.tokenizer.eos_token_id\n",
    "          )\n",
    "    return proc.tokenizer.decode(out[0], skip_special_tokens=True).strip()\n",
    "\n",
    "for i in range(18):\n",
    "    pt = MASK_DIR / f\"{i:03d}_siglip_tokens.pt\"\n",
    "    if not pt.exists():\n",
    "        print(f\"[{i:03d}]  ⨯ file missing\"); continue\n",
    "\n",
    "    obj = torch.load(pt, map_location=\"cpu\", weights_only=False)\n",
    "    mtk = obj[\"mask_token\"]                                  \n",
    "    if mtk.numel() == 0:\n",
    "        print(f\"[{i:03d}]  ⨯ empty\"); continue\n",
    "\n",
    "    ans = ask_llava(mtk)\n",
    "    print(f\"[{i:03d}]  {ans}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d27a293e-e1f6-4277-92f2-e5ad2b088ea1",
   "metadata": {},
   "source": [
    "# # Global Token 추가 LLaVA 답변 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a7f818b7-da71-4d45-afd3-610fff3e1aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global Token : 원본 Image를 SigLIP에 입력해 Token으로 만듦\n",
    "\n",
    "import torch\n",
    "from pathlib import Path\n",
    "from transformers import AutoProcessor, LlavaOnevisionForConditionalGeneration\n",
    "\n",
    "ROOT = Path(\"/home/s2behappy4/data/gyuhyeong/code/siglip_token_demo/hazelnut/hole\")\n",
    "ROOT2 = Path(\"/home/s2behappy4/data/gyuhyeong/code/siglip_mask_token/hazelnut/hole\")\n",
    "MASK = ROOT2\n",
    "GLOB = ROOT / \"good\"\n",
    "MODEL = \"llava-hf/llava-onevision-qwen2-7b-ov-hf\"\n",
    "DEV   = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "DTYPE = torch.bfloat16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ff23a4-a664-4877-9286-9590965a3532",
   "metadata": {},
   "outputs": [],
   "source": [
    "proc  = AutoProcessor.from_pretrained(MODEL, trust_remote_code=True)\n",
    "llava = LlavaOnevisionForConditionalGeneration.from_pretrained(\n",
    "          MODEL, torch_dtype=DTYPE, device_map=\"auto\",\n",
    "          low_cpu_mem_usage=True, trust_remote_code=True).eval()\n",
    "\n",
    "tok_img = proc.tokenizer.additional_special_tokens[0]          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f02cdb4d-d7f8-43a7-ae1e-44dc169c154a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/llava-token/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:636: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.7` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[000]  No, there is no anomaly in the image.\n",
      "[001]  No, there is no anomaly in the image.\n",
      "[002]  No, there is no anomaly in the image.\n",
      "[003]  No, there is no anomaly in the image.\n",
      "[004]  No, there is no anomaly in the image.\n",
      "[005]  No, there is no anomaly in the image.\n",
      "[006]  No, there is no anomaly in the image.\n",
      "[007]  No, there is no anomaly in the image.\n",
      "[008]  No, there is no anomaly in the image.\n",
      "[009]  No, there is no anomaly in the image.\n",
      "[010]  No, there is no anomaly in the image.\n",
      "[011]  No, there is no anomaly in the image.\n",
      "[012]  No, there is no anomaly in the image.\n",
      "[013]  No, there is no anomaly in the image.\n",
      "[014]  No, there is no anomaly in the image.\n",
      "[015]  No, there is no anomaly in the image.\n",
      "[016]  No, there is no anomaly in the image.\n",
      "[017]  No, there is no anomaly in the image.\n"
     ]
    }
   ],
   "source": [
    "for i in range(18):\n",
    "    stem = f\"{i:03d}\"\n",
    "    f_mask = MASK / f\"{stem}_siglip_tokens.pt\"\n",
    "    f_glo  = GLOB / f\"{stem}_global_token.pt\"\n",
    "    if not (f_mask.exists() and f_glo.exists()):\n",
    "        print(f\"[{stem}]  ⨯ token missing\"); continue\n",
    "\n",
    "    d   = torch.load(f_mask, map_location=\"cpu\", weights_only=False)\n",
    "    g   = torch.load(f_glo,  map_location=\"cpu\", weights_only=False)[\"global_token\"]\n",
    "    tok = torch.cat([g.unsqueeze(0), d[\"mask_token\"]], dim=0).to(DEV, DTYPE)  \n",
    "    with torch.no_grad():\n",
    "        v_emb = llava.multi_modal_projector(tok.unsqueeze(0))                 \n",
    "\n",
    "    N = v_emb.size(1)\n",
    "    user_prompt = \"USER: Is there any anomaly in the image? (Yes / No)\\nASSISTANT:\"\n",
    "    prompt = (tok_img + \" \") * N + user_prompt        \n",
    "    tok_in = proc.tokenizer(prompt, return_tensors=\"pt\").to(DEV)\n",
    "    t_emb  = llava.get_input_embeddings()(tok_in.input_ids).to(DTYPE)\n",
    "    att_img = torch.ones(1, N, dtype=torch.long, device=DEV)\n",
    "\n",
    "    inp      = torch.cat([v_emb, t_emb], dim=1)\n",
    "    att_mask = torch.cat([att_img, tok_in.attention_mask], dim=1)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        gen = llava.generate(\n",
    "                inputs_embeds=inp, attention_mask=att_mask,\n",
    "                max_new_tokens=30, temperature=0.7, do_sample=False,\n",
    "                eos_token_id=proc.tokenizer.eos_token_id,\n",
    "                pad_token_id=proc.tokenizer.eos_token_id)\n",
    "    ans = proc.tokenizer.decode(gen[0], skip_special_tokens=True).strip()\n",
    "    print(f\"[{stem}]  {ans}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
