{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ae2b521-c741-42c9-9eff-c00fb0e8bec1",
   "metadata": {},
   "source": [
    "# # Text Embedding Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89cfaf3c-ba88-4e57-adc9-c415d051539b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from huggingface_hub import login\n",
    "from getpass import getpass\n",
    "import gc\n",
    "\n",
    "LLM_MODEL_NAME = \"meta-llama/Meta-Llama-3.1-8B-Instruct\"\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "SAVE_PATH = \"target_embeddings_grid.pt\"\n",
    "\n",
    "try:\n",
    "    token = getpass(\"Hugging Face Access Token: \")\n",
    "    login(token=token)\n",
    "    print(\"Hugging Face login successful\")\n",
    "except Exception as e:\n",
    "    print(f\"{e}\")\n",
    "\n",
    "print(f\"Model to load: {LLM_MODEL_NAME}\")\n",
    "print(f\"Device: {DEVICE}\")\n",
    "\n",
    "llm_model = None\n",
    "llm_tokenizer = None\n",
    "\n",
    "try:\n",
    "    llm_model = AutoModelForCausalLM.from_pretrained(\n",
    "        LLM_MODEL_NAME, \n",
    "        torch_dtype=torch.bfloat16\n",
    "    ).to(DEVICE)\n",
    "    \n",
    "    llm_tokenizer = AutoTokenizer.from_pretrained(LLM_MODEL_NAME)\n",
    "    llm_model.eval()\n",
    "except Exception as e:\n",
    "    print(f\"{e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7088777-7233-4f80-85d6-334c64685b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if llm_model is not None and llm_tokenizer is not None:   \n",
    "    text_normal = \"a photo of a normal region on a grid\"\n",
    "    text_anomaly = \"a photo of an anomaly region on a grid\"\n",
    "    \n",
    "    print(f\"Target text (Normal): '{text_normal}'\")\n",
    "    print(f\"Target text (Anomaly): '{text_anomaly}'\")\n",
    "\n",
    "    try:\n",
    "        with torch.no_grad():\n",
    "            normal_tokens = llm_tokenizer(text_normal, return_tensors=\"pt\").input_ids.to(DEVICE)\n",
    "            embedding_normal = llm_model.get_input_embeddings()(normal_tokens).mean(dim=1).squeeze(0)\n",
    "\n",
    "            anomaly_tokens = llm_tokenizer(text_anomaly, return_tensors=\"pt\").input_ids.to(DEVICE)\n",
    "            embedding_anomaly = llm_model.get_input_embeddings()(anomaly_tokens).mean(dim=1).squeeze(0)\n",
    "\n",
    "        target_embeddings = {\n",
    "            \"normal\": embedding_normal.cpu(),\n",
    "            \"anomaly\": embedding_anomaly.cpu()\n",
    "        }\n",
    "        torch.save(target_embeddings, SAVE_PATH)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"{e}\")\n",
    "    \n",
    "    del llm_model\n",
    "    del llm_tokenizer\n",
    "    gc.collect()\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "    print(\"\\nLLM has been unloaded from memory\")\n",
    "else:\n",
    "    print(\"\\nModel was not loaded successfully\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
